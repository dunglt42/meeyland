https://stackoverflow.com/questions/75214174/how-to-transfer-data-from-source-kafka-cluster-to-target-kafka-cluster-using-kaf

version: '3.3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM_VERSION:-3.0.0}
    ports:
    - "2181:2181"
    - "2888:2888"
    - "3888:3888"
    healthcheck:
      test: echo stat | nc localhost 2181
      interval: 10s
      timeout: 10s
      retries: 3
    environment:
    - ZOOKEEPER_SERVER_ID=1
    - ZOOKEEPER_CLIENT_PORT=2181
    - ZOOKEEPER_TICK_TIME=2000
    - ZOOKEEPER_INIT_LIMIT=5
    - ZOOKEEPER_SYNC_LIMIT=2
    - ZOOKEEPER_SERVERS=zookeeper:2888:3888
  kafka1:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-3.0.0}
    healthcheck:
      test: ps augwwx | egrep [S]upportedKafka
    depends_on:
    - zookeeper
    ports:
    - "9091:9091"
    environment:
    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.241:9091
    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9091
    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_BROKER_ID=1
    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
    - ZOOKEEPER=zookeeper:2181
  kafka2:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-3.0.0}
    healthcheck:
      test: ps augwwx | egrep [S]upportedKafka
    depends_on:
    - zookeeper
    ports:
    - "9092:9092"
    environment:
    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.241:9092
    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_BROKER_ID=2
    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
    - ZOOKEEPER=zookeeper:2181
  kafka3:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-3.0.0}
    healthcheck:
      test: ps augwwx | egrep [S]upportedKafka
    depends_on:
    - zookeeper
    ports:
    - "9093:9093"
    environment:
    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.241:9093
    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9093
    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_BROKER_ID=3
    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
    - ZOOKEEPER=zookeeper:2181

#!/usr/bin/env bash

# Overview:
# 1) Get list of all topic names
# 2) Iterate list, dumping each one to json

# Pre-reqs:
# 1) kafkacat
# 2) jq

mkdir ./output

broker="b-1.meeyland-test.ketxgx.c3.kafka.ap-southeast-1.amazonaws.com:9092,b-2.meeyland-test.ketxgx.c3.kafka.ap-southeast-1.amazonaws.com:9092,b-3.meeyland-test.ketxgx.c3.kafka.ap-southeast-1.amazonaws.com:9092"
broker2="10.100.10.241:9091,10.100.10.241:9092,10.100.10.241:9093"

topics=$(kafkacat -b ${broker} -L -J | jq -r '.topics[].topic' | sort)

for topic in $topics; do
    # Ignore "private"/"internal" topics. Adjust as needed.
    if [[ $topic == "_"* ]]; then
        continue
    fi
    echo "Dumping $topic"
    
    kafkacat -b ${broker} -C -J -e -q -o beginning -t "${topic}" > "./output/$topic.json"
	#kafkacat -b ${broker} -C -J -e -q -o beginning -t "${topic}" | kafkacat -b ${broker2} -P -t "${topic}" -K: 
done

echo "Done!"


###############################
version: '3.3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM_VERSION:-7.6.1}
    ports:
    - "2181:2181"
    - "2888:2888"
    - "3888:3888"
    healthcheck:
      test: echo stat | nc localhost 2181
      interval: 10s
      timeout: 10s
      retries: 3
    environment:
    - ZOOKEEPER_SERVER_ID=1
    - ZOOKEEPER_CLIENT_PORT=2181
    - ZOOKEEPER_TICK_TIME=2000
    - ZOOKEEPER_INIT_LIMIT=5
    - ZOOKEEPER_SYNC_LIMIT=2
    - ZOOKEEPER_SERVERS=zookeeper:2888:3888
  kafka1:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.6.1}
    healthcheck:
      test: ps augwwx | egrep [S]upportedKafka
    depends_on:
    - zookeeper
    ports:
    - "9091:9091"
    environment:
    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.241:9091
    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9091
    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_BROKER_ID=1
    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
    - ZOOKEEPER=zookeeper:2181
  kafka2:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.6.1}
    healthcheck:
      test: ps augwwx | egrep [S]upportedKafka
    depends_on:
    - zookeeper
    ports:
    - "9092:9092"
    environment:
    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.241:9092
    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_BROKER_ID=2
    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
    - ZOOKEEPER=zookeeper:2181
  kafka3:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.6.1}
    healthcheck:
      test: ps augwwx | egrep [S]upportedKafka
    depends_on:
    - zookeeper
    ports:
    - "9093:9093"
    environment:
    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.241:9093
    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9093
    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_BROKER_ID=3
    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
    - ZOOKEEPER=zookeeper:2181
  akhq:
    image: tchiotludo/akhq
    ports:
      - "8080:8080"
    environment:
      - AKHQ_LISTENERS=0.0.0.0:8080
      - AKHQ_KAFKA_BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
    volumes:
      - ./application.yml:/app/application.yml


xong rồi nhé Dung 
10.100.10.241 port 8181
admin/e7p*x8*ZgyxKsjJ

journalctl -f

/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server 10.100.10.241:9091,10.100.10.241:9092,10.100.10.241:9093 --list

/usr/local/kafka/bin/kafka-topics.sh --create --bootstrap-server 10.100.10.241:9091,10.100.10.241:9092,10.100.10.241:9093 --replication-factor 3 --partitions 50 --topic demo

/usr/local/kafka/bin/kafka-console-producer.sh --broker-list 10.100.10.241:9091,10.100.10.241:9092,10.100.10.241:9093 --topic demo

/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server 10.100.10.241:9091,10.100.10.241:9092,10.100.10.241:9093 --topic demo --from-beginning

##############

mkdir -p /data/stg/zookeeper/
mkdir -p /data/stg/kafka-logs1
mkdir -p /data/stg/kafka-logs2
mkdir -p /data/stg/kafka-logs3

### vim /etc/systemd/system/zookeeper-stg.service
[Unit]
Description=Apache Zookeeper server
Documentation=http://zookeeper.apache.org
Requires=network.target remote-fs.target
After=network.target remote-fs.target

[Service]
Type=simple
ExecStart=/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper-stg.properties
ExecStop=/usr/local/kafka/bin/zookeeper-server-stop.sh
Restart=on-abnormal

[Install]
WantedBy=multi-user.target

###
systemctl restart zookeeper-stg
systemctl enable zookeeper-stg

### kafka config
vim /usr/local/kafka/config/server1-stg.properties

broker.id=1
listeners=PLAINTEXT://10.100.10.241:19091
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/data/stg/kafka-logs1
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=10.100.10.241:12181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
delete.topic.enable=true

vim /usr/local/kafka/config/server2-stg.properties

broker.id=2
listeners=PLAINTEXT://10.100.10.241:19092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/data/stg/kafka-logs2
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=10.100.10.241:12181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
delete.topic.enable=true

vim /usr/local/kafka/config/server3-stg.properties

broker.id=3
listeners=PLAINTEXT://10.100.10.241:19093
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/data/stg/kafka-logs3
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=10.100.10.241:12181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
delete.topic.enable=true

### vim /etc/systemd/system/kafka1-stg.service
[Unit]
Description=Apache Kafka Server
Documentation=http://kafka.apache.org/documentation.html
Requires=zookeeper.service

[Service]
Type=simple
Environment="JAVA_HOME=/usr/lib/jvm/java-1.11.0-openjdk-amd64" 
ExecStart=/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server1-stg.properties
ExecStop=/usr/local/kafka/bin/kafka-server-stop.sh

[Install]
WantedBy=multi-user.target

### stop, start service
systemctl restart kafka1-stg
systemctl enable kafka1-stg

### vim /etc/systemd/system/kafka2-stg.service
[Unit]
Description=Apache Kafka Server
Documentation=http://kafka.apache.org/documentation.html
Requires=zookeeper.service

[Service]
Type=simple
Environment="JAVA_HOME=/usr/lib/jvm/java-1.11.0-openjdk-amd64" 
ExecStart=/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server2-stg.properties
ExecStop=/usr/local/kafka/bin/kafka-server-stop.sh

[Install]
WantedBy=multi-user.target

### stop, start service
systemctl restart kafka2-stg
systemctl enable kafka2-stg

### vim /etc/systemd/system/kafka3-stg.service
[Unit]
Description=Apache Kafka Server
Documentation=http://kafka.apache.org/documentation.html
Requires=zookeeper.service

[Service]
Type=simple
Environment="JAVA_HOME=/usr/lib/jvm/java-1.11.0-openjdk-amd64" 
ExecStart=/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server3-stg.properties
ExecStop=/usr/local/kafka/bin/kafka-server-stop.sh

[Install]
WantedBy=multi-user.target

### stop, start service
systemctl restart kafka3-stg
systemctl enable kafka3-stg

kafkacat -b ${broker} -X auto.offset.reset=earliest -K: -G cg01 "${topic}" | kafkacat -b ${broker2} -t "${topic}" -K: -P

### AKHQ

akhq:
    image: tchiotludo/akhq
    ports:
      - "8080:8080"
    environment:
      - AKHQ_LISTENERS=0.0.0.0:8080
      - AKHQ_KAFKA_BOOTSTRAP_SERVERS=10.100.10.241:9091,10.100.10.241:9092,10.100.10.241:9093
    volumes:
      - ./application.yml:/app/application.yml


### Docker
# WARNING: This docker-compose.yml is only for testing purpose.
# Parameters:
# - name: CONFLUENT_PLATFORM_VERSION
#   default: 3.0.0
#   reference: https://hub.docker.com/u/confluentinc/
# Ports:
# - description: Major ports are exposed to host computer
# - zookeeper: 2181
#      kafka1: 9091
#      kafka2: 9092
#      kafka3: 9093
#      kafka4: 9094
#      kafka5: 9095
# Tips:>
#   - You can up part of the cluster with below command.
#     $ docker-compose up -d kafka1 kafka2 kafka3

version: '3.3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM_VERSION:-3.0.0}
    ports:
    - "2181:2181"
    - "2888:2888"
    - "3888:3888"
    healthcheck:
      test: echo stat | nc localhost 2181
      interval: 10s
      timeout: 10s
      retries: 3
    environment:
    - ZOOKEEPER_SERVER_ID=1
    - ZOOKEEPER_CLIENT_PORT=2181
    - ZOOKEEPER_TICK_TIME=2000
    - ZOOKEEPER_INIT_LIMIT=5
    - ZOOKEEPER_SYNC_LIMIT=2
    - ZOOKEEPER_SERVERS=zookeeper:2888:3888
#  kafka1:
#    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-3.0.0}
#    healthcheck:
#      test: ps augwwx | egrep [S]upportedKafka
#    depends_on:
#    - zookeeper
#    ports:
#    - "9091:9091"
#    environment:
#    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.180:9091
#    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9091
#    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
#    - KAFKA_BROKER_ID=1
#    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
#    - ZOOKEEPER=zookeeper:2181
#  kafka2:
#    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-3.0.0}
#    healthcheck:
#      test: ps augwwx | egrep [S]upportedKafka
#    depends_on:
#    - zookeeper
#    ports:
#    - "9092:9092"
#    environment:
#    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.180:9092
#    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
#    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
#    - KAFKA_BROKER_ID=2
#    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
#    - ZOOKEEPER=zookeeper:2181
#  kafka3:
#    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-3.0.0}
#    healthcheck:
#      test: ps augwwx | egrep [S]upportedKafka
#    depends_on:
#    - zookeeper
#    ports:
#    - "9093:9093"
#    environment:
#    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://10.100.10.180:9093
#    - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9093
#    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
#    - KAFKA_BROKER_ID=3
#    - BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092,kafka3:9093
#    - ZOOKEEPER=zookeeper:2181      